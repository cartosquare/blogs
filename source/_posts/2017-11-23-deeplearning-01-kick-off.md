---
title: 深度学习之一：Kick Off
date: 2017-11-23 22:00:10
categories:
  - 算法
tags:
  - 深度学习
  - 机器学习
---

从这篇博客开始，我打算写一系列关于深度学习的文章，旨在梳理深度学习的各个相关组成结构，并探索相应的实现细节。每篇文章可能只会涉及比较小的一个idea，并尽量用caffe2这个库去解读/实现。
<!-- more -->

## 什么是机器学习
顾名思议，机器学习是让机器进行学习的一门学问。机器学习通过喂给电脑大量的先验知识，让电脑了解数据的分布规律，从而使得电脑具备对数据进行预测的能力。比如，给电脑喂大量带标签的图片（标签表明图片里是什么）之后，我们随便给一个电脑没有看过的图片，它就能够预测这个图片里面是什么。

总结成数学语言，对于由N个D维训练样本组成的集合 $x_i \in R^D$, 每个样本对应一个标签 $y_i$，其中 $i = 1 ... N$, $y_i \in 1 ... K$，K是数据的总的标签数。机器学习的目的是让电脑得出一个评分函数（score function）$f: R^D -> R^K$, 这个函数可以把某一个训练样本映射为一个标签。评分函数通常写成下面的形式：
$$s_i = f(w, x_i)$$
即该函数是样本X的函数，w是这个函数的参数集合。不同的机器学习算法体现在评分函数的不同上。线性分类器的评分函数是一个线性函数，只带两个参数（斜率和偏移），SVM分类器的评分函数则是高维函数，至于神经网络乃至深度卷积神经网络的评分函数就够复杂了，参数可以达到数千万乃至上亿。

## 机器学习的组成结构
通常在电脑完成学习之后，可以用评分函数对新的数据进行预测。但是学习的过程还需要代价函数，或者叫损失函数（Loss function）来辅助。在学习/训练的过程中，损失函数通常放在评分函数之后，以评分函数的输出和真实的标签为输入，计算出一个损失值。通过这个损失值指导评分函数对其参数进行调整。通过不断的学习，电脑就能够找到合适的一组权重参数，使得评分函数的输出值进入到损失函数能得到一个尽可能小的值。这个调整权重参数的过程实际上是最小化损失函数的过程，这里目前用的最多的是梯度下降算法。

总结一下，机器学习的结构可以分成三部分，第一部分是评分函数，用来模拟人的决策过程；第二部分是损失函数，用来衡量机器的决策和真实决策的差异；第三部分是最小化损失函数的过程，用来调整评分函数的权重。等到训练过程结束，我们便可以单独使用评分函数进行预测。

## 接下来的计划 ...
后续的blog将会围绕机器学习的这三部分进行，下面是初步拟定的大纲：
* Loss function(svm loss, softmax loss/cross entropy...)

* Stochastic gradient decent(batch sgd...)

* Backward propagation(chain-rule, subgradients...)

* Activation layer

* Weight initialization

* Full connected layer(gemm...)

* Convolutional layer

* Pool layer

* Normalization layer

* CNN case study(alexnet, googlenet, vggnet, resnet...)

* Upsample layer

* FCN

* LSTM

* SegNet

* U-Net

* fast-rcnn/faster-rcnn

* YOLO

* SDD

以上列出的是可能会涉及的概念，当然中间还会穿插一些关于影像识别方面的一些具体例子。所有的Blog代码都会基于[caffe2](https://caffe2.ai/)来开发，这得益于caffe2的高度模块化设计，让我们可以不修改源代码也可以添加自定义的层和相关算法。另外caffe2不仅效率高，而且可以运行在多种设备之上，使得我们的学习代码可以具备工程应用的条件。接下来的所有代码都会放在[caffe2_cpp_tutoria](https://github.com/cartosquare/caffe2_cpp_tutorial)这个仓库中。